{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pehfa\\AppData\\Local\\Temp\\ipykernel_4780\\4069723179.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories containing preprocessed images\n",
    "save_directory_real = '../data/interim/face_processed/real'\n",
    "save_directory_fake = '../data/interim/face_processed/fake'\n",
    "\n",
    "# Function to create a DataFrame with image paths and labels\n",
    "def create_image_label_df(real_dir, fake_dir):\n",
    "    real_images = [(os.path.join(real_dir, f), 1) for f in os.listdir(real_dir) if os.path.isfile(os.path.join(real_dir, f))]\n",
    "    fake_images = [(os.path.join(fake_dir, f), 0) for f in os.listdir(fake_dir) if os.path.isfile(os.path.join(fake_dir, f))]\n",
    "    \n",
    "    # Combine real and fake images into one DataFrame\n",
    "    df = pd.DataFrame(real_images + fake_images, columns=['image_path', 'label'])\n",
    "    return df\n",
    "\n",
    "# Create the DataFrame\n",
    "images_df = create_image_label_df(save_directory_real, save_directory_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2400\n",
      "Validation set size: 800\n",
      "Testing set size: 800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTraining Set: 60% of the original dataset.\\nValidation Set: 20% of the original dataset.\\nTesting Set: 20% of the original dataset.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into features and target arrays\n",
    "X = images_df['image_path'].values\n",
    "y = images_df['label'].values\n",
    "\n",
    "# First split to separate out the test set\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Second split to separate out the training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "\n",
    "'''\n",
    "Training Set: 60% of the original dataset.\n",
    "Validation Set: 20% of the original dataset.\n",
    "Testing Set: 20% of the original dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
